{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Warmup\n",
    "\n",
    "# Why is this useful?\n",
    "![alt text](bstree.png \"Our DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9 - Intro to databases\n",
    "\n",
    "### Contents:\n",
    "\n",
    "* Databases - dockerized versions(quickly as it is beyond the course level)\n",
    "* DataTypes\n",
    "* Tables\n",
    "* Joins\n",
    "* Python - SQLAlchemy\n",
    "* SQL + Pandas implementation!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do I need it?\n",
    "\n",
    "* Peristence of data\n",
    "* Csvs might not be suitable anymore:\n",
    "    * No data sanitation\n",
    "    * Cannot share between clients (download continually data from multiple sources and create a single file)\n",
    "    * Permissions handling\n",
    "    * Files can get corrupted, inconsistent, no security, easily deleted etc...\n",
    "    * What if something happens during a write? Your computer crashes? File will have issues\n",
    "    * Parallel writing\n",
    "    * Speed of writing/reading\n",
    "\n",
    "* Lookup in the dataset! Always need to load the whole thing\n",
    "    * DB finds only the required data and returns them\n",
    " \n",
    "## Cons?\n",
    "\n",
    "* Large overhead (DB server vs file)\n",
    "* Bandwidth limits (bottlenecks in connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational databases\n",
    "\n",
    "* optimize storage -> use normalized data - discover relations using joins\n",
    "* normalization of data - each table contains its specific data and relates to others through keys\n",
    "* designed on ACID principle - Atomicity, Consistency, Isolation, Durability\n",
    "- **Atomicity**: Guarantees that each transaction is treated as a single unit, which either completes entirely or not at all.\n",
    "- **Consistency**: Ensures that a transaction only brings the database from one valid state to another, maintaining data integrity.\n",
    "- **Isolation**: Keeps transactions separate from each other until they're completed, preventing concurrent transactions from affecting each other.\n",
    "- **Durability**: Assures that once a transaction is committed, it remains so even in the case of a system failure, ensuring data permanence.\n",
    "\n",
    "* store huge data amount of data -> gigabytes\n",
    "* read it very fast - depending on the design\n",
    "* Many different applications!\n",
    "    * Business\n",
    "    * Web-servers\n",
    "    * Big data\n",
    "    \n",
    "* Protected access with username / password, vpns\n",
    "* Users have specific permissions! Read/write/delete\n",
    "\n",
    "## SQL\n",
    "*Structured Query Language*\n",
    "* Human (easily) readable\n",
    "* Different implementations\n",
    "    * engines: SQLite, MySQL, Oracle, PostgreSQL\n",
    "* SQL is only a language\n",
    "* Data are stored in *Tables* \n",
    "* Connected via *Relations*\n",
    "* NoSQL - MongoDB, CouchDB, DynamoDB - they optimize access speed, instead of storage\n",
    "     * (now storage is cheap), async, scalable and latency optimal\n",
    "* Distributed databases such as Apache Hive - big data databases (map-reduce)\n",
    "* How does Google get this so quickly? \n",
    "![image.png](google.png)\n",
    "\n",
    "\n",
    "\n",
    "### Database Layers\n",
    "![alt text](sql_struktura.png \"sql structures\")\n",
    "\n",
    "\n",
    "we can have more schemas within a single DB server instance -> saves money on hardware, but still limited resources\n",
    "### Tables\n",
    "Outline of today's problems\n",
    "![alt text](stock-db.png \"Our DB\")\n",
    "\n",
    "\n",
    "### Data Types\n",
    "depends on specific application\n",
    "* numeric\n",
    "    * INT, INTEGER, REAL, FLOAT, DOUBLE etc.\n",
    "* strings\n",
    "    * STRING, TEXT, VARCHAR\n",
    "* more specialized\n",
    "    * DATE, TIME etc.\n",
    "\n",
    "\n",
    "## How to use it? \n",
    "* Command-line\n",
    "* Python drivers\n",
    "* Programming interface\n",
    "* GUI Interface - [DBeaver](https://dbeaver.io/)\n",
    "* Integration with existing software - MS Office, etc\n",
    "\n",
    "\n",
    "We always **connect to the server**, to establish a connection. Then use a **cursor (client)** to send commands and retreive results the DB prepares for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My problem - I want to keep data about stocks for analysis\n",
    "\n",
    "* Would I always need to download data which does not chage?\n",
    "* Run different queries - analysis\n",
    "* More stocks can be added any day\n",
    "* Keep format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import time\n",
    "msft = yf.Ticker(\"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data like this so what do I want to keep? and how?\n",
    "msft.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets create a database for this data\n",
    "\n",
    "* Where to store it?\n",
    "  *  memory: fast, will be lost once exited\n",
    "  * personal computer - why not, but can be lost, ?performance?\n",
    "  * cloud server - SaaS - https://aws.amazon.com/rds/postgresql/ - nice tutorials online, costs money though\n",
    "\n",
    "\n",
    "* Demo - postgresql server instance running in Docker on your computer - quick to start using, no installation etc.\n",
    "  * ! docker will create a container where the data will be stored - if you lose the image, you lose the data!\n",
    "  * It is possible to create have the data in a specific directory, thus persistent - if you really really need persistence of the data, get the cloud server, or read the manual https://hub.docker.com/_/postgres\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which docker image? \n",
    "https://hub.docker.com/_/postgres\n",
    "    \n",
    "docker allows me to easily specify versions, size of image and other things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if you have docker running on your machine, you can easily start the database from terminal / command line\n",
    "\n",
    "* I am running latest postgres 12 based on alpine linux system (dont really care when in docker, but it is slim)\n",
    "* Specifying the image name `--name your name` - I can stop it `docker stop name` and start it again `docker start name`\n",
    "   * if not supplied, it will be created by docker with some funny adjective of a scientist like 'crazy einstein' etc.\n",
    "* specify env variables which will customize the DB (password and postgres user)\n",
    "* specify on which port I can access the db -p 5423:5432 `-p 54322:5432` - in the docker it runs on default postgres 5432, I want to get there through my own 54322 port, since nothing is running there. \n",
    "\n",
    "* recommending add `-d` so it runs in backgroung\n",
    "\n",
    "* access logs `docker logs stock-db`\n",
    "\n",
    "\n",
    "`docker run -d --name stock-db -e POSTGRES_PASSWORD=iesFTW -e POSTGRES_USER=honza -p 54322:5432 postgres:12-alpine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to connect?\n",
    "\n",
    "* Now we have a server - we need a client (like with requests - browser)\n",
    "   * Not a bad idea to get familiar with command line tools `psql` client  - on MacOS `brew install libpq`\n",
    "   * GUI clients - multiplatform https://dbeaver.io/ and others  - on macOS `brew cask install dbeaver-community`   \n",
    " \n",
    "* terminal connect:\n",
    "   * `psql -h localhost -U honza postgres` and put in password `iesFTW`\n",
    "   * `\\dt+` command to show all tables\n",
    "   * default database name is `postgres`, thats the last parameter. You can customize it with docker\n",
    "   * by default `psql` would connect you to database with name same as the user (jansila) in my case, so do not get confused here\n",
    " \n",
    "* DBeaver as shown in video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crucial commands\n",
    "\n",
    "* CREATE TABLE\n",
    "* INSERT INTO ... VALUES ....\n",
    "* SELECT * FROM ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data types\n",
    "\n",
    "like in python - int, string (varchar, text), float, boolean, even json, arrays, coordinates etc..\n",
    "https://www.postgresql.org/docs/10/datatype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save some data - design a database\n",
    "\n",
    "# determine appropriate structure!\n",
    "\n",
    "# tables - company, financials, prices\n",
    "# each has own purpose\n",
    "\n",
    "sql_create_company = \"\"\" CREATE TABLE IF NOT EXISTS company (\n",
    "                            ticker VARCHAR(5) PRIMARY KEY, --max length of a ticker is 5\n",
    "                            name TEXT NOT NULL, --cannot be empty\n",
    "                            sector TEXT,\n",
    "                            state TEXT,\n",
    "                            summary TEXT);\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sql_create_financials = \"\"\"CREATE TABLE financials (\n",
    "    ticker VARCHAR(5) PRIMARY KEY, -- in more advanced designs, we would create this as foreign key! only one observation per ticker\n",
    "    shares BIGINT,\n",
    "    div_yield REAL,\n",
    "    beta REAL\n",
    ");\"\"\"\n",
    "\n",
    "sql_create_prices = \"\"\"CREATE TABLE IF NOT EXISTS prices (\n",
    "    ticker VARCHAR(5),\n",
    "    ts DATE NOT NULL,\n",
    "    price REAL,\n",
    "    volume BIGINT --in milions, important to check the size of the integer not t oget overflow\n",
    "    );\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see in DBeaver if the tables were created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets connect\n",
    "import psycopg2 #only for PostgreSQL\n",
    "from psycopg2 import errors\n",
    "\n",
    "connection = psycopg2.connect(\"dbname='postgres' user='honza' host='db' password='iesFTW'\") \n",
    "connection.autocommit = True #bit advanced\n",
    "# in order to work with the DB, we need a cursor \n",
    "\n",
    "cursor = connection.cursor() #this object interacts with the DB with a proper protocol - like browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate sql create table statements\n",
    "for sql_statement in [sql_create_company, sql_create_financials, sql_create_prices]:\n",
    "    print(sql_statement)\n",
    "    cursor.execute(sql_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_company_data(cursor, ticker, td):\n",
    "    cursor.execute(\"INSERT INTO company (ticker, name, sector, state, summary) VALUES (%s, %s, %s, %s, %s)\", \n",
    "                       (ticker, td.get('shortName'), td.get('sector'), td['state'], td['longBusinessSummary'])\n",
    "                  )\n",
    "def write_financial_data(cursor, ticker, td):\n",
    "    cursor.execute(\"INSERT INTO financials (ticker, shares, div_yield, beta) VALUES (%s, %s, %s, %s)\", \n",
    "                       (ticker, td['floatShares'], td.get('dividendYield',0),td['beta'])\n",
    "                  )\n",
    "\n",
    "def write_prices(cursor, ticker, data):\n",
    "    for row in data.iterrows():\n",
    "        ts = row[0]\n",
    "        close = row[1]['Close']\n",
    "        vol = row[1]['Volume']\n",
    "        cursor.execute(\"INSERT INTO prices (ticker, ts, price, volume) VALUES (%s, %s, %s, %s)\", \n",
    "                       (ticker, ts, close,vol)\n",
    "                  )\n",
    "        \n",
    "## add some data in the db\n",
    "tickers = ['MSFT', 'META','GOOG','GS','INTC', 'AAL', 'AAPL']\n",
    "\n",
    "#yf api https://aroussi.com/post/python-yahoo-finance\n",
    "\n",
    "for ticker in tickers: \n",
    "    td = yf.Ticker(ticker)\n",
    "    print(f'processing {ticker}')\n",
    "    #write some company info and then check it\n",
    "    # try:\n",
    "    write_company_data(cursor, ticker, td.info)\n",
    "    # except errors.UniqueViolation as e:\n",
    "    #     print(e)\n",
    "    \n",
    "    write_financial_data(cursor, ticker, td.info)    \n",
    "    write_prices(cursor, ticker, td.history('ytd'))\n",
    "    \n",
    "print('we are done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM company;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all companies we downloaded\n",
    "\n",
    "cursor.execute(\"SELECT ticker, name, sector FROM company;\")\n",
    "\n",
    "for row in cursor.fetchall(): #cursor.fetchone(), \n",
    "    print(f'downloaded {row[1]} that operates in {row[2]} and has ticker: {row[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.fetchall() #now on the second calll, this is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT ticker, name, sector from company;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.fetchone() #we can get new data by parts -> less requirement on our storage, DB will feed it sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or iterate \n",
    "cursor.execute(\"SELECT ticker, name, sector from company;\")\n",
    "\n",
    "for row in cursor:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all technology companies we downloaded - 3 cases\n",
    "# -------------------------------------\n",
    "#df[df.sector=='Tech'] #where clause\n",
    " \n",
    "#case 1\n",
    "cursor.execute(\"SELECT ticker, name FROM company WHERE sector = 'Technology';\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f'downloaded {row[1]} and has ticker: {row[0]}')\n",
    "\n",
    "# print('-----')\n",
    "#check all technology companies we downloaded\n",
    "#case 2\n",
    "# cursor.execute(\"SELECT ticker, name from company where sector = %s;\", ('Technology', )) #input needs to be a tuple! (single_tuple_has_comma,)\n",
    "# for row in cursor.fetchall():\n",
    "#     print(f'downloaded a tech company {row[1]} and has ticker: {row[0]}')\n",
    "    \n",
    "    \n",
    "    \n",
    "# print('-----')\n",
    "\n",
    "#check all Tech and Industrial companies we downloaded\n",
    "#case 3\n",
    "# for industry in [('Technology',), ('Industrials',)]:\n",
    "\n",
    "#     cursor.execute(\"SELECT ticker, name from company where sector = %s;\", industry) #input needs to be a tuple!\n",
    "#     for row in cursor.fetchall():\n",
    "#         print(f'downloaded a {industry[0]} company {row[1]} and has ticker: {row[0]}')\n",
    "\n",
    "#check multiple sectors at the same time? \n",
    "# industries=('Technology','Industrials')\n",
    "# cursor.execute(\"SELECT ticker, name from company where sector in %s;\", (industries,))\n",
    "# for row in cursor.fetchall():\n",
    "#     print(row)\n",
    "#     print(f'downloaded companies for {industries} {row[1]} and has ticker: {row[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins\n",
    "# just like in pandas\n",
    "\n",
    "# I have information in company table as well as financials which I wan to use at the same time!\n",
    "\n",
    "cursor.execute(\"\"\"SELECT comp.ticker, comp.sector, fin.shares \n",
    "                    \n",
    "                    from company as comp \n",
    "                    \n",
    "                        join financials as fin \n",
    "                    \n",
    "                    on fin.ticker=comp.ticker\n",
    "                ;\"\"\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f'ticker {row[0]} in sector {row[1]} with {row[2]} shares outstanding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JOINS \n",
    "\n",
    "* connecting tables - relations!\n",
    "\n",
    "<img src='https://4.bp.blogspot.com/-_HsHikmChBI/VmQGJjLKgyI/AAAAAAAAEPw/JaLnV0bsbEo/s1600/sql%2Bjoins%2Bguide%2Band%2Bsyntax.jpg' width=\"800\" />\n",
    "\n",
    "### Inner\n",
    "* most common - give me the match!\n",
    "* when you see match, keep it, otherwise drop it.\n",
    "\n",
    "### Left \n",
    "* INNER + rows from LEFT with no match in the RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT comp.ticker, comp.sector, fin.shares \n",
    "                    from company as comp \n",
    "                       left join financials as fin \n",
    "                    on fin.ticker=comp.ticker;\"\"\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f'ticker {row[0]} in sector {row[1]} with {row[2]} shares outstanding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import *\n",
    "import pandas as pd\n",
    "\n",
    "#                 connect as driver://username:password@host:port/database\n",
    "engine = create_engine('postgresql://honza:iesFTW@db:5432/postgres') #postgresql.connection - similar object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas + psycopg2\n",
    "\n",
    "pd.read_sql_query(\"\"\"SELECT comp.ticker, comp.sector, fin.shares \n",
    "                    from company as comp \n",
    "                       left join financials as fin \n",
    "                    on fin.ticker=comp.ticker;\"\"\", connection, index_col='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas + sqlalchemy\n",
    "pd.read_sql_query(\n",
    "\"\"\"SELECT comp.ticker, comp.sector, fin.shares \n",
    "                    from company as comp \n",
    "                       left join financials as fin \n",
    "                    on fin.ticker=comp.ticker;\"\"\"\n",
    "    ,con=engine,index_col='ticker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple joins with WHERE clause!\n",
    "\n",
    "pd.read_sql_query(\"\"\"SELECT comp.ticker, fin.shares,fin.div_yield, px.price as lprice\n",
    "                    \n",
    "                    from company as comp \n",
    "                        \n",
    "                        join financials as fin\n",
    "                            on fin.ticker=comp.ticker\n",
    "                        \n",
    "                        join prices as px\n",
    "                            on px.ticker=comp.ticker\n",
    "                        \n",
    "                        WHERE px.ts='2022-03-18'\n",
    "                  \"\"\",connection, index_col='ticker')\n",
    "\n",
    "#SQL has order of business, it selects on WHERE, then joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='sql_order.png' width=\"1800\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algebra within a query\n",
    "\n",
    "pd.read_sql_query(\"\"\"SELECT comp.ticker, fin.shares, px.price as lprice, fin.shares*px.price/1e9 as mktcap_in_billions\n",
    "                    from company as comp \n",
    "                        join financials as fin\n",
    "                            on fin.ticker=comp.ticker\n",
    "                        join prices as px\n",
    "                            on px.ticker=comp.ticker\n",
    "                        where px.ts='2020-01-02'\n",
    "                  \"\"\",connection, index_col='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all prices and calculated market caps\n",
    "\n",
    "pd.read_sql_query(\"\"\"SELECT comp.ticker, px.price as lprice, px.ts, fin.shares*px.price/1e9 as mktcap_in_billions\n",
    "                    from company as comp \n",
    "                        join financials as fin\n",
    "                            on fin.ticker=comp.ticker\n",
    "                        join prices as px\n",
    "                            on px.ticker=comp.ticker;\n",
    "                  \"\"\",connection, index_col='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create turnover variable\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "                ALTER TABLE prices \n",
    "             ADD COLUMN IF NOT EXISTS turnover REAL;\n",
    "             \"\"\")\n",
    "\n",
    "cursor.execute(\"UPDATE prices SET turnover = volume*price\") #df['turnover']=df.volume*df.price\n",
    "\n",
    "pd.read_sql_query(\"\"\"SELECT * from prices WHERE ticker='AAPL';\n",
    "                  \"\"\",connection, index_col='ticker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANITIZE YOUR INPUTS\n",
    "\n",
    "<Img src='https://imgs.xkcd.com/comics/exploits_of_a_mom.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
